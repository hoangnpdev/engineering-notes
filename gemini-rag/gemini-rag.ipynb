{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0dbdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Models configured: Using local embeddings and Gemini LLM.\n",
      "üìñ Loading documents...\n",
      "Loaded 4379 document(s).\n",
      "‚öôÔ∏è Creating index... (This may take a moment for the first time)\n",
      "‚úÖ Index created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = 'AIzaSyCjHcoB6iJsLiEpqCTA2uaeBLKY8xO0Kkc'\n",
    "# --- 1. Set up API Key for Gemini LLM ---\n",
    "# This is for the generation step, not for embeddings.\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Provide your Google API Key: \")\n",
    "\n",
    "# --- 2. Configure the models in LlamaIndex Settings ---\n",
    "\n",
    "# Use a local model for embeddings (runs on your machine)\n",
    "# This model will be downloaded automatically on the first run.\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "safety_settings = [\n",
    "    {\n",
    "        \"category\": types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        \"threshold\": types.HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "    {\n",
    "        \"category\": types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        \"threshold\": types.HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "    {\n",
    "        \"category\": types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        \"threshold\": types.HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "    {\n",
    "        \"category\": types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        \"threshold\": types.HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "]\n",
    "# Use Google's Gemini Pro model for generation (requires API key)\n",
    "Settings.llm = GoogleGenAI(model=\"models/gemini-2.5-flash-preview-05-20\", safety_settings=safety_settings)\n",
    "\n",
    "print(\"‚úÖ Models configured: Using local embeddings and Gemini LLM.\")\n",
    "\n",
    "\n",
    "# --- 3. Load your data ---\n",
    "# Make sure you have a 'data' folder with text files in it.\n",
    "print(\"üìñ Loading documents...\")\n",
    "documents = SimpleDirectoryReader(\"./redshift\").load_data()\n",
    "print(f\"Loaded {len(documents)} document(s).\")\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, get_response_synthesizer\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "# --- 4. Create the index ---\n",
    "# LlamaIndex will use your local embedding model to turn documents into vectors.\n",
    "print(\"‚öôÔ∏è Creating index... (This may take a moment for the first time)\")\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "print(\"‚úÖ Index created successfully.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2a0c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.response_synthesizers import get_response_synthesizer, ResponseMode\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=3,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=ResponseMode.SIMPLE_SUMMARIZE,\n",
    "    text_qa_template=PromptTemplate(\"\"\"\n",
    "You are an aws expert, trying to explain aws concepts concisely.\n",
    "--------------------\n",
    "Reference:\n",
    "{context_str}\n",
    "--------------------\n",
    "Question: {query_str}\n",
    "Answer:\n",
    "\"\"\")\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5d491d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(persist_dir=\"./redshift-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763cdc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE: \n",
      "\n",
      "No, you cannot use Redshift Spectrum without having your own Redshift cluster.\n",
      "\n",
      "While Redshift Spectrum processes data on dedicated Amazon Redshift servers that are independent of your cluster and allows you to query data in Amazon S3 without loading it into Redshift tables, you still need a Redshift cluster to:\n",
      "*   Initiate and run the queries.\n",
      "*   Define and manage the external tables using DDL commands.\n",
      "*   Act as the endpoint for your queries.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# retrieves = query_engine.retrieve(\"what are values of concurrency scaling mode?\")\n",
    "\n",
    "# if not retrieves:\n",
    "#     print(\"No relevant content was retrieved for this query.\")\n",
    "# else:\n",
    "#     for i, node_with_score in enumerate(retrieves):\n",
    "#         print(f\"--- Document Chunk {i+1} ---\")\n",
    "#         print(node_with_score.node.get_content())\n",
    "#         print(\"-\" * 5 + \"\\n\") # Separator for clarity\n",
    "\n",
    "import textwrap\n",
    "response = query_engine.query(\"can i use redshift spectrum without having my own redshift cluster?\")\n",
    "\n",
    "\n",
    "wrapped_text = textwrap.fill(response, width=120) #text is the object which you want to print\n",
    "print(\"RESPONSE: \\n\")\n",
    "print()\n",
    "print(wrapped_text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
